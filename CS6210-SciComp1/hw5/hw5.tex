\documentclass[12pt]{article}

\usepackage[margin=1in]{geometry}
\usepackage{amsmath,amsthm,amssymb}
\usepackage{float}
\usepackage{graphicx}
\usepackage{bbold}
\usepackage{algorithm}
\usepackage{algcompatible}
\usepackage{csquotes}
\usepackage{url}

\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\abs}[1]{\left| #1 \right|}
\newcommand{\norm}[1]{\left|\left| #1 \right|\right|}
\newcommand{\ceil}[1]{\left\lceil #1 \right\rceil}
\newcommand{\floor}[1]{\left\lfloor #1 \right\rfloor}
\newcommand{\pprime}{\prime \prime}
\newcommand{\BigO}[1]{\mathcal{O}\left( #1 \right)}
\newcommand{\proj}[2][]{\textit{proj}_{\vect{#1}}\vect{#2}}
\newcommand{\vect}{\mathbf}
\newcommand{\Id}{\mathbb{1}}
\newcommand{\inv}[1]{ #1^{-1}}
\newcommand{\minn}{\text{min}}
\newcommand{\maxx}{\text{max}}
\renewcommand{\P}[1]{\left( #1 \right)}

\newenvironment{theorem}[2][Theorem]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{lemma}[2][Lemma]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{exercise}[2][Exercise]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{problem}[2][Problem]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{question}[2][Question]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{corollary}[2][Corollary]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}

\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}

\DeclareMathOperator{\sech}{sech}
\DeclareMathOperator{\csch}{csch}

\begin{document}

\title{CS6210: Homework 5}
\author{Christopher Mertin}
\date{November 22, 2016}
\maketitle

\begin{enumerate}
%%%%%% Problem 1 %%%%%%
\item An $n \times n$ linear system of equations $A\vect{x} = \vect{b}$ is modified
in the following manner: For each $i = \{1,\ldots,n\}$, the value $b_{i}$ on
the right-hand side of the $i^{\text{th}}$ equation is replaced by $b_{i} - x_{i}^{3}$.
Obviously, the modified system of equations (for the unknowns $x_{i}$) is now nonlinear.

\begin{enumerate}
  \item Find the corresponding Jacobian Matrix

  {\bf Solution:}

  \item Given that $A$ is strictly diagonally dominant with positive elements on
  its diagonal, state whether or not it is guarenteed that the Jacobian matrix at
  each iterate is nonsingular.

  {\bf Solution:}

  \item Suppose that $A$ is symmetric positive definition (not necessarily
  diagonally dominant) and that Newton's method is applied to solve the nonlinear
  system. Is it guarenteed to converge?

  {\bf Solution:}

\end{enumerate}

%%%%%% Problem 2 %%%%%%
\item \

\begin{enumerate}
  \item Suppose Newton's method is applied to a linear system $A\vect{x} = \vect{b}$.
  How does the iterative formula look and how many iterations does it take to converge?

  {\bf Solution:}

  \item Suppose the Jacobian matrix is singular at the solution of a nonlinear system
  of equations. Speculate what can occur in terms of convergence and the rate of convergence.
  Specifically, is it possible to have a situation where the newton iteration converges but
  convergence is not quadratic?

  {\bf Solution:}

\end{enumerate}

%%%%%% Problem 3 %%%%%%
\item Consider minimizing the function $\phi(\vect{x}) = \vect{c}^{T}\vect{x} + \frac{1}{2}\vect{x}^{T}H\vect{x}$,
where $\vect{c} = \left( 5.04,-59.4,146.4,-96.6\right)^{T}$ and

\[
  H = \begin{pmatrix}0.16 & -1.2 & 2.4 & -1.4 \\
                     -1.2 & 12.0 & -27.0 & 16.8\\
                     2.4  & -27.0 & 64.8 & -42.0\\
                     -1.4 & 16.8 & -42.0 & 28.0\end{pmatrix}
\]

Try both Newton and BFGS methods, starting from $\vect{x}_{0} = \left( -1,3,3,0\right)^{T}$.
Explain why the BFGS method requires significantly more iterations than Newton's.

{\bf Solution:}


%%%%%% Problem 4 %%%%%%
\item Wit the notation of Exercise 21, for $p = 2$ the problem can be solved as
in Example 9.15 using SVD. But it can also be solved using thge techniques of
constrained optimization:

\begin{enumerate}
  \item Explain why it is justified to replace the objective function by $\frac{1}{2}\norm{y}_{2}^{2}$.

  {\bf Solution:}

  \item Form the KKT conditions of the resulting constrained optimization problem,
  obtaining a linear system of equations.

  {\bf Solution:}

  \item Devise an example and solve it using the method developed as well as the one
  from Example 9.15. Compare and discuss.

  {\bf Solution:}

\end{enumerate}

%%%%%% Problem 5 %%%%%%
\item Given the four data points $(-1, 1), (0,1), (1,2), (2,0)$, determine the
interpolating cubic polynomial

\begin{itemize}
  \item Using the monomial basis
  \item Using the Lagrange basis
  \item Using the Newton basis
\end{itemize}

Show that the three representations give the same polynomial.

{\bf Solution:}


%%%%%% Problem 6 %%%%%%
\item Suppose we are given 137 uniformly spaced data pairs at distinct abscissae:
$\left( x_{i}, y_{i}\right),i = 0,1,\ldots,136$. These data are thought to represent
a function which is piecewise smooth; that is, the unknown function $f(x)$ which
gave rise to these data values has many bounded derivatives everywhere expect for
a few points where it jups discontinuously. (Imagine drawing a curve smoothly from
left to right, mixed with lifting the pen and moving it vertically a few times.)
For each sub interval $[x_{i-1},x_{i}]$ we wanit to pass the hopefully best cubic
$p_{3}(x)$ for an accurate interpolation of $f(x)$ at points $x_{i-1}<x<x_{i}$.
This involves choosing good neighbors to interpolate at.

Propose an algorithm for this task. Justify.

{\bf Solution:}


%%%%%% Problem 7 %%%%%%
\item A popular technique arising in methods for minimizing functions in several
variables involves a {\em weak line search}, where an approximate minimum $\widetilde{x}$
is found for a function in one variable, $f(x)$, for whcih the values of $f(0)$,
$f^{\prime}(0)$, and $f(1)$ are given. The function $f(x)$ is defined for all
nonnegative $x$, has a continuous second derivative, and satisfies $f(0) < f(1)$
and $f^{\prime}(0) < 0$. We then interpolate the given values by a quadratic polynomial
and set $\widetilde{x}$ as the minimum of the interpolant.

\begin{enumerate}
  \item Find $\widetilde{x}$ for the values of $f(0) = 1$, $f^{\prime}(0) = -1$, $f(1) = 2$

  {\bf Solution:}

\item Show that the quadratic interpolant has a unique minimum satisfying $0 < \widetilde{x} < 1$.
Can you show the same for the function $f$ itself?

{\bf Solution:}

\end{enumerate}

%%%%%% Problem 8 %%%%%%
\item Let $f \in C^{3}[a,b]$ be given at equidistant points $x_{i} = a + ih$, $i = \{0,1,\ldots,n\}$,
where $nh = b-a$. Assume further that $f^{\prime}(a)$ is given as well.

\begin{enumerate}
  \item Construct an algorithm for $C^{1}$ piecewise quadratic interpolation of the
  given values. Thus, the interpolating function is written as

  \[
    v(x) = s_{i}(s) = a_{i} + b_{i}\left( x - x_{i}\right) + c_{i}\left( x-x_{i}\right)^{2},\quad x_{i} \leq x \leq x_{i+1}
  \]

  for $i = \{0,\ldots,n-1\}$, and your job is to specify an algorithm for determining
  the $3n$ coefficients $a_{i}$, $b_{i}$, and $c_{i}$.

  {\bf Solution:}

  \item How accurate do you expect this approximation to be as a function of $h$? Justify.

  {\bf Solution:}

\end{enumerate}

%%%%%% Problem 9 %%%%%%
\item Derive a B-spline basis representation for piecewise linear interplation and
for piecewise Hermite cubic interpolation.

{\bf Solution:}


%%%%%% Problem 10 %%%%%%
\item Consider interpolating the data $\left(x_{0}, y_{0}\right),\ldots,\left(x_{6}, y_{6}\right)$
given by

\begin{table}[H]
  \centering
  \begin{tabular}{| c | c | c | c | c | c | c | c |}
    $x$ & 0.1 & 0.15 & 0.2 & 0.3 & 0.35 & 0.5 & 0.75\\
    \hline
    $y$ & 3.0 & 2.0 & 1.2 & 2.1 & 2.0 & 2.5 & 2.5
  \end{tabular}
\end{table}

Construct the five interpolants specified below (you may use available software
for this), evaluate them at the points $\{ 0.05, 0.06,\ldots,0.80\}$, plot, and
comment on their respective properties:

\begin{enumerate}
  \item Polynomial Interpolant

  {\bf Solution:}

  \item Cubic Spline Interpolant

  {\bf Solution:}

  \item The Interpolant

  \[
      v(x) = \sum_{j=0}^{n}c_{j}\phi_{j}(x)
  \]

  where $n = 7$, $\phi_{0}(x) = 1$, and

  \[
      \phi_{j}(x) = \sqrt{\left( x - x_{j-1}\right)^{2} + \epsilon^{2}} - \epsilon
  \]

  In addition to the $n$ interpolation requirements, the condition $c_{0} = -\sum_{j=1}^{n}c_{j}$
  is imposed. Construct this interpolant with
    \begin{enumerate}
      \item $\epsilon = 0.1$

      {\bf Solution:}

      \item $\epsilon = 0.01$

      {\bf Solution:}

      \item $\epsilon = 0.001$

      {\bf Solution:}
    \end{enumerate}

  Make as many observations as you can. What will happen if we let $\epsilon \rightarrow 0$?

  {\bf Solution:}


\end{enumerate}

\end{enumerate}

%\begin{proof}
%Blah, blah, blah.  Here is an example of the \texttt{align} environment:
%Note 1: The * tells LaTeX not to number the lines.  If you remove the *, be sure to remove it below, too.
%Note 2: Inside the align environment, you do not want to use $-signs.  The reason for this is that this is already a math environment. This is why we have to include \text{} around any text inside the align environment.
%\begin{align*}
%\sum_{i=1}^{k+1}i & = \left(\sum_{i=1}^{k}i\right) +(k+1)\\
%& = \frac{k(k+1)}{2}+k+1 & (\text{by inductive hypothesis})\\
%& = \frac{k(k+1)+2(k+1)}{2}\\
%& = \frac{(k+1)(k+2)}{2}\\
%& = \frac{(k+1)((k+1)+1)}{2}.
%\end{align*}
%\end{proof}

\end{document}
